{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIJrqt6xFZBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVUw2mMVFZBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e9ee8f77-ddbb-4f80-8670-1d2cac671ef1"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgL8fgmkFZBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset =s[:,2:-1] pd.read_csv('Churn_Modelling.csv')\n",
        "x = dataset.value\n",
        "y = dataset.values[:,-1]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ki9qtkmFZBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeBl3dfxHc34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Encoder1 = LabelEncoder()\n",
        "Encoder1.fit(np.unique(x[:,3]))\n",
        "x[:,3] = Encoder1.transform(x[:,3])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we7JPvzXId4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder,LabelBinarizer"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXXLr1irTyxb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nkZNLcaIkPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lbz = LabelBinarizer()\n",
        "lali = x[:,3:]\n",
        "p = np.concatenate((x[:,:3],lbz.fit_transform(x[:,2])),axis=1)\n",
        "xed = np.append(p,lali,axis=1)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfFrLjvQRZUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.delete(xed,2,1)\n",
        "x = np.delete(x,0,1)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un0vSK9aUMYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKofiuuDUnDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyjw91niVP3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HayUH99jVTYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann.add(layer=tf.keras.layers.ELU())\n",
        "ann.add(layer=tf.keras.layers.Dense(units=8, activation='relu'))"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJFG_EmBbYlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann.add(layer=tf.keras.layers.Dense(units=8, activation='relu'))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqZGwLQ6czm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann.add(layer=tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez7JdO4Of2jN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig_b4dOihLjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.asarray(x_train).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylwnA9O5f4dh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4930c062-1258-418b-a4ac-6a060236dd59"
      },
      "source": [
        "ann.fit(x_train, y_train, batch_size= 32, epochs= 500)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.6692 - accuracy: 0.6808\n",
            "Epoch 2/500\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.6105 - accuracy: 0.7945\n",
            "Epoch 3/500\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.5737 - accuracy: 0.7945\n",
            "Epoch 4/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.5489 - accuracy: 0.7945\n",
            "Epoch 5/500\n",
            "250/250 [==============================] - 0s 915us/step - loss: 0.5321 - accuracy: 0.7945\n",
            "Epoch 6/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.5185 - accuracy: 0.7945\n",
            "Epoch 7/500\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.5043 - accuracy: 0.7945\n",
            "Epoch 8/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7945\n",
            "Epoch 9/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.4708 - accuracy: 0.7945\n",
            "Epoch 10/500\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.4600 - accuracy: 0.7945\n",
            "Epoch 11/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.4520 - accuracy: 0.7945\n",
            "Epoch 12/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.4455 - accuracy: 0.7945\n",
            "Epoch 13/500\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.4408 - accuracy: 0.8020\n",
            "Epoch 14/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.4366 - accuracy: 0.8249\n",
            "Epoch 15/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.4333 - accuracy: 0.8292\n",
            "Epoch 16/500\n",
            "250/250 [==============================] - 0s 898us/step - loss: 0.4298 - accuracy: 0.8284\n",
            "Epoch 17/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.4275 - accuracy: 0.8305\n",
            "Epoch 18/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.4248 - accuracy: 0.8300\n",
            "Epoch 19/500\n",
            "250/250 [==============================] - 0s 983us/step - loss: 0.4221 - accuracy: 0.8305\n",
            "Epoch 20/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.4191 - accuracy: 0.8314\n",
            "Epoch 21/500\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.4158 - accuracy: 0.8321\n",
            "Epoch 22/500\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.4127 - accuracy: 0.8329\n",
            "Epoch 23/500\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.4085 - accuracy: 0.8370\n",
            "Epoch 24/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.4052 - accuracy: 0.8389\n",
            "Epoch 25/500\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.4017 - accuracy: 0.8407\n",
            "Epoch 26/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3983 - accuracy: 0.8413\n",
            "Epoch 27/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3948 - accuracy: 0.8450\n",
            "Epoch 28/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3911 - accuracy: 0.8464\n",
            "Epoch 29/500\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3878 - accuracy: 0.8484\n",
            "Epoch 30/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8503\n",
            "Epoch 31/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3816 - accuracy: 0.8539\n",
            "Epoch 32/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3788 - accuracy: 0.8547\n",
            "Epoch 33/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3757 - accuracy: 0.8564\n",
            "Epoch 34/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3734 - accuracy: 0.8556\n",
            "Epoch 35/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3709 - accuracy: 0.8575\n",
            "Epoch 36/500\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3683 - accuracy: 0.8589\n",
            "Epoch 37/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3664 - accuracy: 0.8576\n",
            "Epoch 38/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3641 - accuracy: 0.8614\n",
            "Epoch 39/500\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3626 - accuracy: 0.8604\n",
            "Epoch 40/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3607 - accuracy: 0.8614\n",
            "Epoch 41/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3595 - accuracy: 0.8599\n",
            "Epoch 42/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3584 - accuracy: 0.8624\n",
            "Epoch 43/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3573 - accuracy: 0.8612\n",
            "Epoch 44/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3561 - accuracy: 0.8612\n",
            "Epoch 45/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3548 - accuracy: 0.8618\n",
            "Epoch 46/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8621\n",
            "Epoch 47/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3534 - accuracy: 0.8619\n",
            "Epoch 48/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3520 - accuracy: 0.8622\n",
            "Epoch 49/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3514 - accuracy: 0.8614\n",
            "Epoch 50/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3510 - accuracy: 0.8629\n",
            "Epoch 51/500\n",
            "250/250 [==============================] - 0s 967us/step - loss: 0.3503 - accuracy: 0.8620\n",
            "Epoch 52/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3496 - accuracy: 0.8609\n",
            "Epoch 53/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3496 - accuracy: 0.8618\n",
            "Epoch 54/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3487 - accuracy: 0.8606\n",
            "Epoch 55/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8627\n",
            "Epoch 56/500\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3479 - accuracy: 0.8619\n",
            "Epoch 57/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3470 - accuracy: 0.8618\n",
            "Epoch 58/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3474 - accuracy: 0.8635\n",
            "Epoch 59/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3466 - accuracy: 0.8627\n",
            "Epoch 60/500\n",
            "250/250 [==============================] - 0s 983us/step - loss: 0.3460 - accuracy: 0.8609\n",
            "Epoch 61/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3464 - accuracy: 0.8619\n",
            "Epoch 62/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3454 - accuracy: 0.8606\n",
            "Epoch 63/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3454 - accuracy: 0.8625\n",
            "Epoch 64/500\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.3448 - accuracy: 0.8634\n",
            "Epoch 65/500\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3444 - accuracy: 0.8626\n",
            "Epoch 66/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8621\n",
            "Epoch 67/500\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3438 - accuracy: 0.8629\n",
            "Epoch 68/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3434 - accuracy: 0.8619\n",
            "Epoch 69/500\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3434 - accuracy: 0.8633\n",
            "Epoch 70/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3433 - accuracy: 0.8622\n",
            "Epoch 71/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3427 - accuracy: 0.8633\n",
            "Epoch 72/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3431 - accuracy: 0.8626\n",
            "Epoch 73/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3428 - accuracy: 0.8636\n",
            "Epoch 74/500\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3426 - accuracy: 0.8620\n",
            "Epoch 75/500\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3416 - accuracy: 0.8633\n",
            "Epoch 76/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3418 - accuracy: 0.8631\n",
            "Epoch 77/500\n",
            "250/250 [==============================] - 0s 900us/step - loss: 0.3417 - accuracy: 0.8624\n",
            "Epoch 78/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3415 - accuracy: 0.8604\n",
            "Epoch 79/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3413 - accuracy: 0.8618\n",
            "Epoch 80/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3413 - accuracy: 0.8625\n",
            "Epoch 81/500\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3414 - accuracy: 0.8615\n",
            "Epoch 82/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3409 - accuracy: 0.8622\n",
            "Epoch 83/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3408 - accuracy: 0.8616\n",
            "Epoch 84/500\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3407 - accuracy: 0.8619\n",
            "Epoch 85/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3402 - accuracy: 0.8624\n",
            "Epoch 86/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3397 - accuracy: 0.8616\n",
            "Epoch 87/500\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3401 - accuracy: 0.8625\n",
            "Epoch 88/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3398 - accuracy: 0.8622\n",
            "Epoch 89/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3396 - accuracy: 0.8633\n",
            "Epoch 90/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3398 - accuracy: 0.8629\n",
            "Epoch 91/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3393 - accuracy: 0.8627\n",
            "Epoch 92/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3397 - accuracy: 0.8614\n",
            "Epoch 93/500\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3391 - accuracy: 0.8645\n",
            "Epoch 94/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3393 - accuracy: 0.8620\n",
            "Epoch 95/500\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3393 - accuracy: 0.8631\n",
            "Epoch 96/500\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3394 - accuracy: 0.8640\n",
            "Epoch 97/500\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3389 - accuracy: 0.8618\n",
            "Epoch 98/500\n",
            "250/250 [==============================] - 0s 896us/step - loss: 0.3384 - accuracy: 0.8627\n",
            "Epoch 99/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3377 - accuracy: 0.8645\n",
            "Epoch 100/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3381 - accuracy: 0.8639\n",
            "Epoch 101/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3382 - accuracy: 0.8622\n",
            "Epoch 102/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3382 - accuracy: 0.8633\n",
            "Epoch 103/500\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3379 - accuracy: 0.8635\n",
            "Epoch 104/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3381 - accuracy: 0.8622\n",
            "Epoch 105/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3380 - accuracy: 0.8629\n",
            "Epoch 106/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3382 - accuracy: 0.8622\n",
            "Epoch 107/500\n",
            "250/250 [==============================] - 0s 928us/step - loss: 0.3376 - accuracy: 0.8629\n",
            "Epoch 108/500\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3375 - accuracy: 0.8629\n",
            "Epoch 109/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8631\n",
            "Epoch 110/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3378 - accuracy: 0.8626\n",
            "Epoch 111/500\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3378 - accuracy: 0.8660\n",
            "Epoch 112/500\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3370 - accuracy: 0.8637\n",
            "Epoch 113/500\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3372 - accuracy: 0.8630\n",
            "Epoch 114/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3364 - accuracy: 0.8622\n",
            "Epoch 115/500\n",
            "250/250 [==============================] - 0s 899us/step - loss: 0.3369 - accuracy: 0.8635\n",
            "Epoch 116/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3363 - accuracy: 0.8643\n",
            "Epoch 117/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3369 - accuracy: 0.8625\n",
            "Epoch 118/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3363 - accuracy: 0.8635\n",
            "Epoch 119/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3365 - accuracy: 0.8654\n",
            "Epoch 120/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3360 - accuracy: 0.8648\n",
            "Epoch 121/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3366 - accuracy: 0.8609\n",
            "Epoch 122/500\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3357 - accuracy: 0.8654\n",
            "Epoch 123/500\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3360 - accuracy: 0.8645\n",
            "Epoch 124/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3368 - accuracy: 0.8635\n",
            "Epoch 125/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3354 - accuracy: 0.8637\n",
            "Epoch 126/500\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3357 - accuracy: 0.8644\n",
            "Epoch 127/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3362 - accuracy: 0.8616\n",
            "Epoch 128/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3353 - accuracy: 0.8641\n",
            "Epoch 129/500\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3358 - accuracy: 0.8646\n",
            "Epoch 130/500\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3356 - accuracy: 0.8641\n",
            "Epoch 131/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3352 - accuracy: 0.8640\n",
            "Epoch 132/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3354 - accuracy: 0.8646\n",
            "Epoch 133/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3354 - accuracy: 0.8637\n",
            "Epoch 134/500\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3345 - accuracy: 0.8633\n",
            "Epoch 135/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3356 - accuracy: 0.8650\n",
            "Epoch 136/500\n",
            "250/250 [==============================] - 0s 892us/step - loss: 0.3348 - accuracy: 0.8651\n",
            "Epoch 137/500\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.3351 - accuracy: 0.8640\n",
            "Epoch 138/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3344 - accuracy: 0.8646\n",
            "Epoch 139/500\n",
            "250/250 [==============================] - 0s 967us/step - loss: 0.3350 - accuracy: 0.8643\n",
            "Epoch 140/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3343 - accuracy: 0.8648\n",
            "Epoch 141/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3347 - accuracy: 0.8631\n",
            "Epoch 142/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3350 - accuracy: 0.8641\n",
            "Epoch 143/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3345 - accuracy: 0.8649\n",
            "Epoch 144/500\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3340 - accuracy: 0.8665\n",
            "Epoch 145/500\n",
            "250/250 [==============================] - 0s 899us/step - loss: 0.3346 - accuracy: 0.8635\n",
            "Epoch 146/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3343 - accuracy: 0.8631\n",
            "Epoch 147/500\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3342 - accuracy: 0.8656\n",
            "Epoch 148/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3341 - accuracy: 0.8641\n",
            "Epoch 149/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3333 - accuracy: 0.8676\n",
            "Epoch 150/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3346 - accuracy: 0.8637\n",
            "Epoch 151/500\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3344 - accuracy: 0.8651\n",
            "Epoch 152/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3331 - accuracy: 0.8655\n",
            "Epoch 153/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3334 - accuracy: 0.8668\n",
            "Epoch 154/500\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3345 - accuracy: 0.8649\n",
            "Epoch 155/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8650\n",
            "Epoch 156/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3337 - accuracy: 0.8651\n",
            "Epoch 157/500\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.3333 - accuracy: 0.8659\n",
            "Epoch 158/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3336 - accuracy: 0.8662\n",
            "Epoch 159/500\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3335 - accuracy: 0.8636\n",
            "Epoch 160/500\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3332 - accuracy: 0.8666\n",
            "Epoch 161/500\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3334 - accuracy: 0.8661\n",
            "Epoch 162/500\n",
            "250/250 [==============================] - 0s 880us/step - loss: 0.3336 - accuracy: 0.8660\n",
            "Epoch 163/500\n",
            "250/250 [==============================] - 0s 895us/step - loss: 0.3336 - accuracy: 0.8649\n",
            "Epoch 164/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3335 - accuracy: 0.8654\n",
            "Epoch 165/500\n",
            "250/250 [==============================] - 0s 915us/step - loss: 0.3334 - accuracy: 0.8636\n",
            "Epoch 166/500\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3332 - accuracy: 0.8658\n",
            "Epoch 167/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3331 - accuracy: 0.8664\n",
            "Epoch 168/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3330 - accuracy: 0.8635\n",
            "Epoch 169/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3326 - accuracy: 0.8649\n",
            "Epoch 170/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3329 - accuracy: 0.8641\n",
            "Epoch 171/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3330 - accuracy: 0.8646\n",
            "Epoch 172/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3324 - accuracy: 0.8665\n",
            "Epoch 173/500\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3338 - accuracy: 0.8644\n",
            "Epoch 174/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3325 - accuracy: 0.8651\n",
            "Epoch 175/500\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3319 - accuracy: 0.8664\n",
            "Epoch 176/500\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3334 - accuracy: 0.8650\n",
            "Epoch 177/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3331 - accuracy: 0.8658\n",
            "Epoch 178/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3322 - accuracy: 0.8660\n",
            "Epoch 179/500\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.3330 - accuracy: 0.8656\n",
            "Epoch 180/500\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.3317 - accuracy: 0.8641\n",
            "Epoch 181/500\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3327 - accuracy: 0.8659\n",
            "Epoch 182/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3319 - accuracy: 0.8652\n",
            "Epoch 183/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3332 - accuracy: 0.8648\n",
            "Epoch 184/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3323 - accuracy: 0.8650\n",
            "Epoch 185/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3326 - accuracy: 0.8640\n",
            "Epoch 186/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3326 - accuracy: 0.8662\n",
            "Epoch 187/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3324 - accuracy: 0.8654\n",
            "Epoch 188/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3322 - accuracy: 0.8669\n",
            "Epoch 189/500\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3336 - accuracy: 0.8645\n",
            "Epoch 190/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3320 - accuracy: 0.8658\n",
            "Epoch 191/500\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3322 - accuracy: 0.8661\n",
            "Epoch 192/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3320 - accuracy: 0.8699\n",
            "Epoch 193/500\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3325 - accuracy: 0.8643\n",
            "Epoch 194/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3327 - accuracy: 0.8646\n",
            "Epoch 195/500\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3321 - accuracy: 0.8666\n",
            "Epoch 196/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3316 - accuracy: 0.8636\n",
            "Epoch 197/500\n",
            "250/250 [==============================] - 0s 997us/step - loss: 0.3323 - accuracy: 0.8674\n",
            "Epoch 198/500\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3320 - accuracy: 0.8655\n",
            "Epoch 199/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8668\n",
            "Epoch 200/500\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3311 - accuracy: 0.8652\n",
            "Epoch 201/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3320 - accuracy: 0.8680\n",
            "Epoch 202/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3318 - accuracy: 0.8648\n",
            "Epoch 203/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3319 - accuracy: 0.8680\n",
            "Epoch 204/500\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3326 - accuracy: 0.8654\n",
            "Epoch 205/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3322 - accuracy: 0.8665\n",
            "Epoch 206/500\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3314 - accuracy: 0.8651\n",
            "Epoch 207/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3320 - accuracy: 0.8677\n",
            "Epoch 208/500\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3321 - accuracy: 0.8651\n",
            "Epoch 209/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3309 - accuracy: 0.8655\n",
            "Epoch 210/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3321 - accuracy: 0.8625\n",
            "Epoch 211/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3315 - accuracy: 0.8677\n",
            "Epoch 212/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3316 - accuracy: 0.8664\n",
            "Epoch 213/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3311 - accuracy: 0.8661\n",
            "Epoch 214/500\n",
            "250/250 [==============================] - 0s 928us/step - loss: 0.3315 - accuracy: 0.8673\n",
            "Epoch 215/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3314 - accuracy: 0.8676\n",
            "Epoch 216/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3319 - accuracy: 0.8674\n",
            "Epoch 217/500\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3317 - accuracy: 0.8671\n",
            "Epoch 218/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3313 - accuracy: 0.8656\n",
            "Epoch 219/500\n",
            "250/250 [==============================] - 0s 881us/step - loss: 0.3319 - accuracy: 0.8675\n",
            "Epoch 220/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3316 - accuracy: 0.8650\n",
            "Epoch 221/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3310 - accuracy: 0.8654\n",
            "Epoch 222/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3309 - accuracy: 0.8671\n",
            "Epoch 223/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3316 - accuracy: 0.8675\n",
            "Epoch 224/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3317 - accuracy: 0.8660\n",
            "Epoch 225/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3310 - accuracy: 0.8669\n",
            "Epoch 226/500\n",
            "250/250 [==============================] - 0s 892us/step - loss: 0.3311 - accuracy: 0.8659\n",
            "Epoch 227/500\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3305 - accuracy: 0.8668\n",
            "Epoch 228/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3310 - accuracy: 0.8671\n",
            "Epoch 229/500\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3306 - accuracy: 0.8659\n",
            "Epoch 230/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3310 - accuracy: 0.8675\n",
            "Epoch 231/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3314 - accuracy: 0.8685\n",
            "Epoch 232/500\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3310 - accuracy: 0.8661\n",
            "Epoch 233/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3309 - accuracy: 0.8666\n",
            "Epoch 234/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3311 - accuracy: 0.8656\n",
            "Epoch 235/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3306 - accuracy: 0.8658\n",
            "Epoch 236/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3305 - accuracy: 0.8668\n",
            "Epoch 237/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3303 - accuracy: 0.8654\n",
            "Epoch 238/500\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3306 - accuracy: 0.8675\n",
            "Epoch 239/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3310 - accuracy: 0.8666\n",
            "Epoch 240/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3302 - accuracy: 0.8674\n",
            "Epoch 241/500\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3315 - accuracy: 0.8664\n",
            "Epoch 242/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3310 - accuracy: 0.8675\n",
            "Epoch 243/500\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.3309 - accuracy: 0.8665\n",
            "Epoch 244/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3307 - accuracy: 0.8684\n",
            "Epoch 245/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8675\n",
            "Epoch 246/500\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 247/500\n",
            "250/250 [==============================] - 0s 898us/step - loss: 0.3300 - accuracy: 0.8679\n",
            "Epoch 248/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3299 - accuracy: 0.8671\n",
            "Epoch 249/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3303 - accuracy: 0.8676\n",
            "Epoch 250/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3305 - accuracy: 0.8666\n",
            "Epoch 251/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3308 - accuracy: 0.8661\n",
            "Epoch 252/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3306 - accuracy: 0.8650\n",
            "Epoch 253/500\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3298 - accuracy: 0.8681\n",
            "Epoch 254/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3306 - accuracy: 0.8668\n",
            "Epoch 255/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3302 - accuracy: 0.8660\n",
            "Epoch 256/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3307 - accuracy: 0.8658\n",
            "Epoch 257/500\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3307 - accuracy: 0.8668\n",
            "Epoch 258/500\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3303 - accuracy: 0.8681\n",
            "Epoch 259/500\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3296 - accuracy: 0.8666\n",
            "Epoch 260/500\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3303 - accuracy: 0.8655\n",
            "Epoch 261/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3300 - accuracy: 0.8666\n",
            "Epoch 262/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3300 - accuracy: 0.8668\n",
            "Epoch 263/500\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3302 - accuracy: 0.8660\n",
            "Epoch 264/500\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3300 - accuracy: 0.8680\n",
            "Epoch 265/500\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3296 - accuracy: 0.8658\n",
            "Epoch 266/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3298 - accuracy: 0.8662\n",
            "Epoch 267/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3303 - accuracy: 0.8671\n",
            "Epoch 268/500\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3297 - accuracy: 0.8673\n",
            "Epoch 269/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3302 - accuracy: 0.8665\n",
            "Epoch 270/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3294 - accuracy: 0.8679\n",
            "Epoch 271/500\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3299 - accuracy: 0.8685\n",
            "Epoch 272/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3299 - accuracy: 0.8662\n",
            "Epoch 273/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3299 - accuracy: 0.8664\n",
            "Epoch 274/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3298 - accuracy: 0.8676\n",
            "Epoch 275/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3302 - accuracy: 0.8658\n",
            "Epoch 276/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3299 - accuracy: 0.8658\n",
            "Epoch 277/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3292 - accuracy: 0.8668\n",
            "Epoch 278/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3298 - accuracy: 0.8683\n",
            "Epoch 279/500\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3295 - accuracy: 0.8679\n",
            "Epoch 280/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3294 - accuracy: 0.8668\n",
            "Epoch 281/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3289 - accuracy: 0.8670\n",
            "Epoch 282/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3294 - accuracy: 0.8677\n",
            "Epoch 283/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8660\n",
            "Epoch 284/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3292 - accuracy: 0.8671\n",
            "Epoch 285/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3298 - accuracy: 0.8652\n",
            "Epoch 286/500\n",
            "250/250 [==============================] - 0s 894us/step - loss: 0.3292 - accuracy: 0.8694\n",
            "Epoch 287/500\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3303 - accuracy: 0.8658\n",
            "Epoch 288/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8644\n",
            "Epoch 289/500\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3287 - accuracy: 0.8661\n",
            "Epoch 290/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3291 - accuracy: 0.8670\n",
            "Epoch 291/500\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3292 - accuracy: 0.8683\n",
            "Epoch 292/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3303 - accuracy: 0.8665\n",
            "Epoch 293/500\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3297 - accuracy: 0.8671\n",
            "Epoch 294/500\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3289 - accuracy: 0.8675\n",
            "Epoch 295/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3285 - accuracy: 0.8676\n",
            "Epoch 296/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3294 - accuracy: 0.8655\n",
            "Epoch 297/500\n",
            "250/250 [==============================] - 0s 981us/step - loss: 0.3290 - accuracy: 0.8676\n",
            "Epoch 298/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3295 - accuracy: 0.8680\n",
            "Epoch 299/500\n",
            "250/250 [==============================] - 0s 886us/step - loss: 0.3287 - accuracy: 0.8687\n",
            "Epoch 300/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3294 - accuracy: 0.8656\n",
            "Epoch 301/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3295 - accuracy: 0.8662\n",
            "Epoch 302/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8677\n",
            "Epoch 303/500\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3292 - accuracy: 0.8640\n",
            "Epoch 304/500\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3288 - accuracy: 0.8701\n",
            "Epoch 305/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3295 - accuracy: 0.8675\n",
            "Epoch 306/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3286 - accuracy: 0.8664\n",
            "Epoch 307/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3298 - accuracy: 0.8660\n",
            "Epoch 308/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3290 - accuracy: 0.8674\n",
            "Epoch 309/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3290 - accuracy: 0.8669\n",
            "Epoch 310/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3285 - accuracy: 0.8666\n",
            "Epoch 311/500\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3292 - accuracy: 0.8668\n",
            "Epoch 312/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3292 - accuracy: 0.8666\n",
            "Epoch 313/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3288 - accuracy: 0.8679\n",
            "Epoch 314/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3292 - accuracy: 0.8676\n",
            "Epoch 315/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3278 - accuracy: 0.8670\n",
            "Epoch 316/500\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3295 - accuracy: 0.8664\n",
            "Epoch 317/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3288 - accuracy: 0.8671\n",
            "Epoch 318/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3289 - accuracy: 0.8665\n",
            "Epoch 319/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8686\n",
            "Epoch 320/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3292 - accuracy: 0.8671\n",
            "Epoch 321/500\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3296 - accuracy: 0.8673\n",
            "Epoch 322/500\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3288 - accuracy: 0.8673\n",
            "Epoch 323/500\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3288 - accuracy: 0.8683\n",
            "Epoch 324/500\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.3292 - accuracy: 0.8666\n",
            "Epoch 325/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3282 - accuracy: 0.8675\n",
            "Epoch 326/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3287 - accuracy: 0.8684\n",
            "Epoch 327/500\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3283 - accuracy: 0.8660\n",
            "Epoch 328/500\n",
            "250/250 [==============================] - 0s 895us/step - loss: 0.3292 - accuracy: 0.8680\n",
            "Epoch 329/500\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3289 - accuracy: 0.8661\n",
            "Epoch 330/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3291 - accuracy: 0.8658\n",
            "Epoch 331/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3286 - accuracy: 0.8658\n",
            "Epoch 332/500\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3287 - accuracy: 0.8651\n",
            "Epoch 333/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8679\n",
            "Epoch 334/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3288 - accuracy: 0.8665\n",
            "Epoch 335/500\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3292 - accuracy: 0.8670\n",
            "Epoch 336/500\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3291 - accuracy: 0.8669\n",
            "Epoch 337/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3286 - accuracy: 0.8681\n",
            "Epoch 338/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3282 - accuracy: 0.8680\n",
            "Epoch 339/500\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3288 - accuracy: 0.8673\n",
            "Epoch 340/500\n",
            "250/250 [==============================] - 0s 899us/step - loss: 0.3282 - accuracy: 0.8674\n",
            "Epoch 341/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3289 - accuracy: 0.8683\n",
            "Epoch 342/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3285 - accuracy: 0.8683\n",
            "Epoch 343/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3288 - accuracy: 0.8671\n",
            "Epoch 344/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3288 - accuracy: 0.8665\n",
            "Epoch 345/500\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3293 - accuracy: 0.8670\n",
            "Epoch 346/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3287 - accuracy: 0.8665\n",
            "Epoch 347/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3287 - accuracy: 0.8668\n",
            "Epoch 348/500\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3282 - accuracy: 0.8671\n",
            "Epoch 349/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3287 - accuracy: 0.8661\n",
            "Epoch 350/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8679\n",
            "Epoch 351/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3282 - accuracy: 0.8677\n",
            "Epoch 352/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3286 - accuracy: 0.8689\n",
            "Epoch 353/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3288 - accuracy: 0.8661\n",
            "Epoch 354/500\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3288 - accuracy: 0.8668\n",
            "Epoch 355/500\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3282 - accuracy: 0.8664\n",
            "Epoch 356/500\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3279 - accuracy: 0.8669\n",
            "Epoch 357/500\n",
            "250/250 [==============================] - 0s 899us/step - loss: 0.3285 - accuracy: 0.8659\n",
            "Epoch 358/500\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3286 - accuracy: 0.8656\n",
            "Epoch 359/500\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3284 - accuracy: 0.8671\n",
            "Epoch 360/500\n",
            "250/250 [==============================] - 0s 963us/step - loss: 0.3284 - accuracy: 0.8666\n",
            "Epoch 361/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3274 - accuracy: 0.8664\n",
            "Epoch 362/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3286 - accuracy: 0.8651\n",
            "Epoch 363/500\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3279 - accuracy: 0.8690\n",
            "Epoch 364/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3286 - accuracy: 0.8666\n",
            "Epoch 365/500\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3278 - accuracy: 0.8684\n",
            "Epoch 366/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3275 - accuracy: 0.8671\n",
            "Epoch 367/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8677\n",
            "Epoch 368/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3285 - accuracy: 0.8665\n",
            "Epoch 369/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3276 - accuracy: 0.8685\n",
            "Epoch 370/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3289 - accuracy: 0.8670\n",
            "Epoch 371/500\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3287 - accuracy: 0.8658\n",
            "Epoch 372/500\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.3276 - accuracy: 0.8680\n",
            "Epoch 373/500\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3285 - accuracy: 0.8662\n",
            "Epoch 374/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3281 - accuracy: 0.8659\n",
            "Epoch 375/500\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3286 - accuracy: 0.8679\n",
            "Epoch 376/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3279 - accuracy: 0.8661\n",
            "Epoch 377/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3277 - accuracy: 0.8692\n",
            "Epoch 378/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3283 - accuracy: 0.8692\n",
            "Epoch 379/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3283 - accuracy: 0.8685\n",
            "Epoch 380/500\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3280 - accuracy: 0.8665\n",
            "Epoch 381/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3275 - accuracy: 0.8679\n",
            "Epoch 382/500\n",
            "250/250 [==============================] - 0s 898us/step - loss: 0.3282 - accuracy: 0.8669\n",
            "Epoch 383/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8660\n",
            "Epoch 384/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3285 - accuracy: 0.8677\n",
            "Epoch 385/500\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3284 - accuracy: 0.8658\n",
            "Epoch 386/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3281 - accuracy: 0.8702\n",
            "Epoch 387/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3278 - accuracy: 0.8685\n",
            "Epoch 388/500\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3282 - accuracy: 0.8676\n",
            "Epoch 389/500\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3293 - accuracy: 0.8673\n",
            "Epoch 390/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3283 - accuracy: 0.8674\n",
            "Epoch 391/500\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3275 - accuracy: 0.8668\n",
            "Epoch 392/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8680\n",
            "Epoch 393/500\n",
            "250/250 [==============================] - 0s 914us/step - loss: 0.3276 - accuracy: 0.8685\n",
            "Epoch 394/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3277 - accuracy: 0.8680\n",
            "Epoch 395/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3278 - accuracy: 0.8694\n",
            "Epoch 396/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 397/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3277 - accuracy: 0.8660\n",
            "Epoch 398/500\n",
            "250/250 [==============================] - 0s 978us/step - loss: 0.3276 - accuracy: 0.8677\n",
            "Epoch 399/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3278 - accuracy: 0.8676\n",
            "Epoch 400/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3279 - accuracy: 0.8665\n",
            "Epoch 401/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3277 - accuracy: 0.8675\n",
            "Epoch 402/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3277 - accuracy: 0.8675\n",
            "Epoch 403/500\n",
            "250/250 [==============================] - 0s 895us/step - loss: 0.3280 - accuracy: 0.8661\n",
            "Epoch 404/500\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3274 - accuracy: 0.8686\n",
            "Epoch 405/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3274 - accuracy: 0.8669\n",
            "Epoch 406/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3287 - accuracy: 0.8674\n",
            "Epoch 407/500\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3283 - accuracy: 0.8681\n",
            "Epoch 408/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3280 - accuracy: 0.8671\n",
            "Epoch 409/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3272 - accuracy: 0.8675\n",
            "Epoch 410/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3278 - accuracy: 0.8674\n",
            "Epoch 411/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3280 - accuracy: 0.8665\n",
            "Epoch 412/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3269 - accuracy: 0.8681\n",
            "Epoch 413/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3282 - accuracy: 0.8662\n",
            "Epoch 414/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3278 - accuracy: 0.8668\n",
            "Epoch 415/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3280 - accuracy: 0.8684\n",
            "Epoch 416/500\n",
            "250/250 [==============================] - 0s 896us/step - loss: 0.3280 - accuracy: 0.8679\n",
            "Epoch 417/500\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3277 - accuracy: 0.8681\n",
            "Epoch 418/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3277 - accuracy: 0.8690\n",
            "Epoch 419/500\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3271 - accuracy: 0.8660\n",
            "Epoch 420/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3282 - accuracy: 0.8668\n",
            "Epoch 421/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3278 - accuracy: 0.8652\n",
            "Epoch 422/500\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3274 - accuracy: 0.8684\n",
            "Epoch 423/500\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3278 - accuracy: 0.8662\n",
            "Epoch 424/500\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3273 - accuracy: 0.8686\n",
            "Epoch 425/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3277 - accuracy: 0.8677\n",
            "Epoch 426/500\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3272 - accuracy: 0.8668\n",
            "Epoch 427/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3273 - accuracy: 0.8668\n",
            "Epoch 428/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3274 - accuracy: 0.8687\n",
            "Epoch 429/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3279 - accuracy: 0.8675\n",
            "Epoch 430/500\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3277 - accuracy: 0.8666\n",
            "Epoch 431/500\n",
            "250/250 [==============================] - 0s 928us/step - loss: 0.3275 - accuracy: 0.8673\n",
            "Epoch 432/500\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.3277 - accuracy: 0.8689\n",
            "Epoch 433/500\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.3277 - accuracy: 0.8668\n",
            "Epoch 434/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3274 - accuracy: 0.8681\n",
            "Epoch 435/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3282 - accuracy: 0.8676\n",
            "Epoch 436/500\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3270 - accuracy: 0.8684\n",
            "Epoch 437/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3285 - accuracy: 0.8669\n",
            "Epoch 438/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3284 - accuracy: 0.8700\n",
            "Epoch 439/500\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3282 - accuracy: 0.8679\n",
            "Epoch 440/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3274 - accuracy: 0.8675\n",
            "Epoch 441/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3281 - accuracy: 0.8677\n",
            "Epoch 442/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3280 - accuracy: 0.8648\n",
            "Epoch 443/500\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3276 - accuracy: 0.8687\n",
            "Epoch 444/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3277 - accuracy: 0.8676\n",
            "Epoch 445/500\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3280 - accuracy: 0.8675\n",
            "Epoch 446/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3275 - accuracy: 0.8684\n",
            "Epoch 447/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8679\n",
            "Epoch 448/500\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3285 - accuracy: 0.8660\n",
            "Epoch 449/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3274 - accuracy: 0.8681\n",
            "Epoch 450/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3270 - accuracy: 0.8676\n",
            "Epoch 451/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3275 - accuracy: 0.8666\n",
            "Epoch 452/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3274 - accuracy: 0.8683\n",
            "Epoch 453/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3273 - accuracy: 0.8679\n",
            "Epoch 454/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3280 - accuracy: 0.8679\n",
            "Epoch 455/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3272 - accuracy: 0.8669\n",
            "Epoch 456/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3274 - accuracy: 0.8664\n",
            "Epoch 457/500\n",
            "250/250 [==============================] - 0s 893us/step - loss: 0.3274 - accuracy: 0.8665\n",
            "Epoch 458/500\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.3272 - accuracy: 0.8669\n",
            "Epoch 459/500\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.3280 - accuracy: 0.8676\n",
            "Epoch 460/500\n",
            "250/250 [==============================] - 0s 979us/step - loss: 0.3272 - accuracy: 0.8683\n",
            "Epoch 461/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3272 - accuracy: 0.8675\n",
            "Epoch 462/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3283 - accuracy: 0.8673\n",
            "Epoch 463/500\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3279 - accuracy: 0.8671\n",
            "Epoch 464/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8681\n",
            "Epoch 465/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3273 - accuracy: 0.8684\n",
            "Epoch 466/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3274 - accuracy: 0.8668\n",
            "Epoch 467/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3271 - accuracy: 0.8683\n",
            "Epoch 468/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8679\n",
            "Epoch 469/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3272 - accuracy: 0.8679\n",
            "Epoch 470/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3279 - accuracy: 0.8674\n",
            "Epoch 471/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3288 - accuracy: 0.8656\n",
            "Epoch 472/500\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3281 - accuracy: 0.8669\n",
            "Epoch 473/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3276 - accuracy: 0.8660\n",
            "Epoch 474/500\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 475/500\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3265 - accuracy: 0.8673\n",
            "Epoch 476/500\n",
            "250/250 [==============================] - 0s 995us/step - loss: 0.3275 - accuracy: 0.8676\n",
            "Epoch 477/500\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3273 - accuracy: 0.8698\n",
            "Epoch 478/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3269 - accuracy: 0.8675\n",
            "Epoch 479/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3271 - accuracy: 0.8651\n",
            "Epoch 480/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3270 - accuracy: 0.8681\n",
            "Epoch 481/500\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3273 - accuracy: 0.8685\n",
            "Epoch 482/500\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3269 - accuracy: 0.8679\n",
            "Epoch 483/500\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3276 - accuracy: 0.8659\n",
            "Epoch 484/500\n",
            "250/250 [==============================] - 0s 914us/step - loss: 0.3276 - accuracy: 0.8687\n",
            "Epoch 485/500\n",
            "250/250 [==============================] - 0s 992us/step - loss: 0.3262 - accuracy: 0.8671\n",
            "Epoch 486/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3274 - accuracy: 0.8674\n",
            "Epoch 487/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3273 - accuracy: 0.8671\n",
            "Epoch 488/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3279 - accuracy: 0.8665\n",
            "Epoch 489/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3283 - accuracy: 0.8641\n",
            "Epoch 490/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3272 - accuracy: 0.8679\n",
            "Epoch 491/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3275 - accuracy: 0.8651\n",
            "Epoch 492/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3266 - accuracy: 0.8679\n",
            "Epoch 493/500\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3266 - accuracy: 0.8679\n",
            "Epoch 494/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3275 - accuracy: 0.8686\n",
            "Epoch 495/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3270 - accuracy: 0.8675\n",
            "Epoch 496/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3273 - accuracy: 0.8679\n",
            "Epoch 497/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3274 - accuracy: 0.8640\n",
            "Epoch 498/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3273 - accuracy: 0.8684\n",
            "Epoch 499/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3269 - accuracy: 0.8668\n",
            "Epoch 500/500\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3268 - accuracy: 0.8687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9803d9b4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLO78Yt0gR1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news = scaler.transform(np.array([[600, 1,0,0,1,\n",
        "                                  40,3,60000,2,1,1,50000]])).astype(np.float32)\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Homework**\n",
        "\n",
        "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card ? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "So, should we say goodbye to that customer ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMX-rvRZjeJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36a08a8f-5018-4311-8ed2-3e5b7dfb9ea0"
      },
      "source": [
        "ann.predict(news)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03739769]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dELWpImrRYUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = (ann.predict(scaler.transform(x_test)) > 0.5).astype(np.float32).reshape(1,-1)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1ilVT2SSRIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkCihvEynKlG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZC-4e1zlaQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE39r0hklpnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "ff331aef-a7f6-4173-d167-c011b8afbdc0"
      },
      "source": [
        "plt.matshow(confusion_matrix(y_pred = y_pred, y_true=y_test.astype(np.float32)))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MClG3t_lnLeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = y_pred.reshape(y_test.shape)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9zgML4gnTQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "52bf4ce2-f5e4-47c2-cf38-34053ba190f4"
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LLrmep5nVLq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "703b74f0-5003-46bc-facb-66e951197866"
      },
      "source": [
        "df_cm = pd.DataFrame(confusion_matrix(y_pred = y_pred, y_true=y_test.astype(np.float32)), \n",
        "                     index = [i for i in \"01\"],\n",
        "                  columns = [i for i in \"01\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.heatmap(df_cm, annot=True)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f97ffa4ac18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUMeNo6eoESb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}